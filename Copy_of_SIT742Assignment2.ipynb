{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SIT742Assignment2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.5.5",
      "name": "python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "kernelspec": {
      "display_name": "Python 3.5",
      "name": "python3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pipsicle/sit742/blob/master/Copy_of_SIT742Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_th7e2nu0At7",
        "colab_type": "text"
      },
      "source": [
        "# SIT742: Modern Data Science \n",
        "**(Assessment Task 02: Bank Marketing Data Analytics)**\n",
        "\n",
        "---\n",
        "- Materials in this module include resources collected from various open-source online repositories.\n",
        "- You are free to use, change and distribute this package.\n",
        "\n",
        "Prepared by **SIT742 Teaching Team**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Project Group Information:**\n",
        "\n",
        "- Names:\n",
        "- Student IDs:\n",
        "- Emails:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eASNvREtBU9G"
      },
      "source": [
        "# 1.Import Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "duCJfMrnGu00",
        "cellView": "code",
        "outputId": "27f9afa3-3324-4069-8155-31a8c26b3813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#Set up environment\n",
        "#Used updated https://www.apache.org/dyn/closer.lua/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz\n",
        "!pip install wget\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aGOo805LA-fM",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K7bEtO_fBZmE"
      },
      "source": [
        "# 2.Read and check data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EADPspOv0Auh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Read and check the data\n",
        "import wget\n",
        "\n",
        "#read data from tulip labs on github and store it as DataSet\n",
        "link_to_data = 'https://github.com/tulip-lab/sit742/raw/master/Assessment/2019/data/bank.csv'\n",
        "DataSet = wget.download(link_to_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiM-PiiR0Aup",
        "colab_type": "code",
        "outputId": "a2d3ca5b-02dc-4514-8857-ee1f57a91beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "#reading the csv file into a spark dataframe\n",
        "spark = SparkSession.builder.appName('ml-bank').getOrCreate()\n",
        "df = spark.read.csv('bank.csv', header = True, inferSchema = True) \n",
        "\n",
        "#check import of csv file, show columns and 5 rows\n",
        "df.printSchema() \n",
        "df.show(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- default: string (nullable = true)\n",
            " |-- balance: integer (nullable = true)\n",
            " |-- housing: string (nullable = true)\n",
            " |-- loan: string (nullable = true)\n",
            " |-- contact: string (nullable = true)\n",
            " |-- day: integer (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- campaign: integer (nullable = true)\n",
            " |-- pdays: integer (nullable = true)\n",
            " |-- previous: integer (nullable = true)\n",
            " |-- poutcome: string (nullable = true)\n",
            " |-- deposit: string (nullable = true)\n",
            "\n",
            "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|age|       job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n",
            "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "| 59|    admin.|married|secondary|     no|   2343|    yes|  no|unknown|  5|  may|    1042|       1|   -1|       0| unknown|    yes|\n",
            "| 56|    admin.|married|secondary|     no|     45|     no|  no|unknown|  5|  may|    1467|       1|   -1|       0| unknown|    yes|\n",
            "| 41|technician|married|secondary|     no|   1270|    yes|  no|unknown|  5|  may|    1389|       1|   -1|       0| unknown|    yes|\n",
            "| 55|  services|married|secondary|     no|   2476|    yes|  no|unknown|  5|  may|     579|       1|   -1|       0| unknown|    yes|\n",
            "| 54|    admin.|married| tertiary|     no|    184|     no|  no|unknown|  5|  may|     673|       2|   -1|       0| unknown|    yes|\n",
            "+---+----------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FQ8Ts9eZBA-M",
        "outputId": "3e21933a-b328-4b78-edf9-eac66bb36807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Check data distribution\n",
        "df.describe().show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+-------+--------+---------+-------+------------------+-------+-----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+-------+\n",
            "|summary|               age|    job| marital|education|default|           balance|housing| loan| contact|               day|month|          duration|          campaign|             pdays|          previous|poutcome|deposit|\n",
            "+-------+------------------+-------+--------+---------+-------+------------------+-------+-----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+-------+\n",
            "|  count|             11162|  11162|   11162|    11162|  11162|             11162|  11162|11162|   11162|             11162|11162|             11162|             11162|             11162|             11162|   11162|  11162|\n",
            "|   mean|41.231947679627304|   null|    null|     null|   null|1528.5385235620856|   null| null|    null|15.658036194230425| null|371.99381831213043| 2.508421429851281| 51.33040673714388|0.8325568894463358|    null|   null|\n",
            "| stddev|11.913369192215518|   null|    null|     null|   null| 3225.413325946149|   null| null|    null| 8.420739541006462| null|347.12838571630687|2.7220771816614824|108.75828197197717| 2.292007218670508|    null|   null|\n",
            "|    min|                18| admin.|divorced|  primary|     no|             -6847|     no|   no|cellular|                 1|  apr|                 2|                 1|                -1|                 0| failure|     no|\n",
            "|    max|                95|unknown|  single|  unknown|    yes|             81204|    yes|  yes| unknown|                31|  sep|              3881|                63|               854|                58| unknown|    yes|\n",
            "+-------+------------------+-------+--------+---------+-------+------------------+-------+-----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wKQMhrtFChHa"
      },
      "source": [
        "# 3.Select features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VU5xMqN_RyM2",
        "outputId": "0954a986-62bd-4b6e-b0a7-5aa72837d5e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "#Select features ('age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'campaign', 'pdays', 'previous', 'poutcome', 'deposit') as df2\n",
        "\n",
        "df2 = df.select('age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'campaign', 'pdays', 'previous', 'poutcome', 'deposit')\n",
        "\n",
        "#Check the data selected\n",
        "df2.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----------+--------+---------+-------+-------+-------+----+--------+-----+--------+--------+-------+\n",
            "|age|        job| marital|education|default|balance|housing|loan|campaign|pdays|previous|poutcome|deposit|\n",
            "+---+-----------+--------+---------+-------+-------+-------+----+--------+-----+--------+--------+-------+\n",
            "| 59|     admin.| married|secondary|     no|   2343|    yes|  no|       1|   -1|       0| unknown|    yes|\n",
            "| 56|     admin.| married|secondary|     no|     45|     no|  no|       1|   -1|       0| unknown|    yes|\n",
            "| 41| technician| married|secondary|     no|   1270|    yes|  no|       1|   -1|       0| unknown|    yes|\n",
            "| 55|   services| married|secondary|     no|   2476|    yes|  no|       1|   -1|       0| unknown|    yes|\n",
            "| 54|     admin.| married| tertiary|     no|    184|     no|  no|       2|   -1|       0| unknown|    yes|\n",
            "| 42| management|  single| tertiary|     no|      0|    yes| yes|       2|   -1|       0| unknown|    yes|\n",
            "| 56| management| married| tertiary|     no|    830|    yes| yes|       1|   -1|       0| unknown|    yes|\n",
            "| 60|    retired|divorced|secondary|     no|    545|    yes|  no|       1|   -1|       0| unknown|    yes|\n",
            "| 37| technician| married|secondary|     no|      1|    yes|  no|       1|   -1|       0| unknown|    yes|\n",
            "| 28|   services|  single|secondary|     no|   5090|    yes|  no|       3|   -1|       0| unknown|    yes|\n",
            "| 38|     admin.|  single|secondary|     no|    100|    yes|  no|       1|   -1|       0| unknown|    yes|\n",
            "| 30|blue-collar| married|secondary|     no|    309|    yes|  no|       2|   -1|       0| unknown|    yes|\n",
            "| 29| management| married| tertiary|     no|    199|    yes| yes|       4|   -1|       0| unknown|    yes|\n",
            "| 46|blue-collar|  single| tertiary|     no|    460|    yes|  no|       2|   -1|       0| unknown|    yes|\n",
            "| 31| technician|  single| tertiary|     no|    703|    yes|  no|       2|   -1|       0| unknown|    yes|\n",
            "| 35| management|divorced| tertiary|     no|   3837|    yes|  no|       1|   -1|       0| unknown|    yes|\n",
            "| 32|blue-collar|  single|  primary|     no|    611|    yes|  no|       3|   -1|       0| unknown|    yes|\n",
            "| 49|   services| married|secondary|     no|     -8|    yes|  no|       1|   -1|       0| unknown|    yes|\n",
            "| 41|     admin.| married|secondary|     no|     55|    yes|  no|       2|   -1|       0| unknown|    yes|\n",
            "| 49|     admin.|divorced|secondary|     no|    168|    yes| yes|       1|   -1|       0| unknown|    yes|\n",
            "+---+-----------+--------+---------+-------+-------+-------+----+--------+-----+--------+--------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vwF5sqRYa_eI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "cfcc7592-6a64-473c-d985-ff9816565921"
      },
      "source": [
        "#Remove invalid rows/records using spark.sql\n",
        "\n",
        "#Creating a local temporary view of df2 for spark.sql as 'bank_table'\n",
        "df2.createOrReplaceTempView('bank_table')\n",
        "\n",
        "#Removing rows where poutcome does not equal either 'success' or 'failure'\n",
        "#Removing any rows where any columns value is equal to 'unknown' (excpet for column poutcome as these values would be removed via 'poutcome IN (\"success\", \"failure\")')\n",
        "df2 = spark.sql('select * from bank_table where poutcome IN (\"success\", \"failure\") AND  \"unknown\" NOT IN (age, job, marital, education, default, balance, housing, loan, campaign, pdays, previous, deposit)')\n",
        "\n",
        "#Check the data\n",
        "df2.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+------------+--------+---------+-------+-------+-------+----+--------+-----+--------+--------+-------+\n",
            "|age|         job| marital|education|default|balance|housing|loan|campaign|pdays|previous|poutcome|deposit|\n",
            "+---+------------+--------+---------+-------+-------+-------+----+--------+-----+--------+--------+-------+\n",
            "| 33|    services| married|secondary|     no|   3444|    yes|  no|       1|   91|       4| failure|    yes|\n",
            "| 56|  technician| married|secondary|     no|    589|    yes|  no|       1|  147|       2| success|    yes|\n",
            "| 34|      admin.| married| tertiary|     no|    899|    yes|  no|       1|  170|       3| failure|    yes|\n",
            "| 53|     retired| married| tertiary|     no|   2269|     no|  no|       2|  150|       1| success|    yes|\n",
            "| 37|  technician| married|secondary|     no|   5115|    yes|  no|       2|  171|       4| failure|    yes|\n",
            "| 45|entrepreneur| married|secondary|     no|    781|     no| yes|       2|  126|       2| failure|    yes|\n",
            "| 46|  unemployed|divorced|secondary|     no|   3354|    yes|  no|       1|  174|       1| success|    yes|\n",
            "| 40|  management| married| tertiary|     no|   3352|    yes|  no|       2|   27|       1| success|    yes|\n",
            "| 32|  technician| married| tertiary|     no|   4654|    yes| yes|       1|  128|       2| failure|    yes|\n",
            "| 30| blue-collar| married|secondary|     no|    501|    yes| yes|       1|  177|       1| failure|    yes|\n",
            "| 46|  technician| married| tertiary|     no|      0|     no|  no|       1|  167|       1| failure|    yes|\n",
            "| 38|entrepreneur| married| tertiary|     no|   1110|    yes|  no|       2|  183|       2| failure|    yes|\n",
            "| 32|    services| married|secondary|     no|    983|    yes|  no|       2|  133|       1| failure|    yes|\n",
            "| 31|  unemployed| married|secondary|     no|    314|    yes|  no|       3|  178|       7| failure|    yes|\n",
            "| 50| blue-collar| married|  primary|     no|  12519|    yes|  no|       3|   34|       1| failure|    yes|\n",
            "| 47|  technician| married|secondary|     no|      0|     no|  no|       1|   10|       1| failure|    yes|\n",
            "| 59|  management| married| tertiary|     no|   7049|     no|  no|       1|  163|       2| failure|    yes|\n",
            "| 31|  management| married|secondary|     no|   8629|    yes|  no|       1|  184|       2| failure|    yes|\n",
            "| 53| blue-collar| married|secondary|     no|   1777|    yes|  no|       5|  154|       1| failure|    yes|\n",
            "| 40|  technician|  single| tertiary|     no|   1646|    yes|  no|       1|  242|       2| failure|    yes|\n",
            "+---+------------+--------+---------+-------+-------+-------+----+--------+-----+--------+--------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A_T8qvxzR-oI",
        "colab": {}
      },
      "source": [
        "#Covert categorical features to metric features using One hot encoding\n",
        "\n",
        "#Using StringIndexer encode a string column to a column of indices\n",
        "#Use One Hot Encoder Estimator to map catergoical features to a binary vector\n",
        "StringColumns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'poutcome']\n",
        "StringColumnsIndVec = []\n",
        "\n",
        "for StringColumn in StringColumns:\n",
        "    stringIndexer = StringIndexer(inputCol = StringColumn, outputCol = StringColumn + 'Index')\n",
        "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[StringColumn + \"classVec\"])\n",
        "    StringColumnsIndVec += [stringIndexer, encoder]\n",
        "\n",
        "#print(StringColumnsIndVec)\n",
        "\n",
        "#use StringIndexer to encode a string column to a column of indices for output variable deposit\n",
        "#Add deposit to StringColumnsIndVec[]\n",
        "label_stringIdx = StringIndexer(inputCol = 'deposit', outputCol = 'label')\n",
        "StringColumnsIndVec += [label_stringIdx]\n",
        "\n",
        "#add numerical columns to StringColumnsIndVec[] \n",
        "numericColumns = ['age', 'balance', 'campaign', 'pdays', 'previous']\n",
        "assemblerInputs = [c + \"classVec\" for c in StringColumns] + numericColumns\n",
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "StringColumnsIndVec += [assembler]\n",
        "\n",
        "#generate df2 column list for selection after pipeline\n",
        "selectedCols = ['label', 'features'] + cols\n",
        "\n",
        "#pipeline data to fit and transform assembled columns \n",
        "pipeline = Pipeline(stages = StringColumnsIndVec)\n",
        "pipelineModel = pipeline.fit(df2)\n",
        "df2 = pipelineModel.transform(df2)\n",
        "\n",
        "df2 = df2.select(selectedCols)\n",
        "\n",
        "#Check df2\n",
        "df2.show()\n",
        "df2.printSchema()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pOqHERYJCQuC"
      },
      "source": [
        "## 3.1 normalisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cfL6_sca5VwI",
        "colab": {}
      },
      "source": [
        "#Apply Min-Max normalisation on each attribute using MinMaxScaler  \n",
        "from pyspark.ml.feature import MinMaxScaler "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9trUY7ZgCzhW"
      },
      "source": [
        "# 4.Unsupervised learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KTQfUch2Cmmi"
      },
      "source": [
        "## 4.1 K-means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dGGZI70Ohqgg",
        "colab": {}
      },
      "source": [
        "# Perform unsupervised learning on df2 with k-means \n",
        "# You can use whole df2 as both training and testing data, \n",
        "# Evaluate the clustering result using Accuracy.  \n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FHom8o2KCt36"
      },
      "source": [
        "## 4.2 PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wT4cx5uGTjmj",
        "colab": {}
      },
      "source": [
        "#Generate a scatter plot using the first two PCA components to investigate the data distribution.\n",
        "from pyspark.ml.feature import PCA\n",
        "from pyspark.ml.linalg import Vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ulp_uILXCv4Z"
      },
      "source": [
        "# 5.Supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0O7tszcPfnHN",
        "colab": {}
      },
      "source": [
        "train, test = df2.randomSplit([0.7, 0.3], seed = 742)\n",
        "print(\"Training Dataset Count: \" + str(train.count()))\n",
        "print(\"Test Dataset Count: \" + str(test.count()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2SsHdh7YC-eN"
      },
      "source": [
        "## 5.1 LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vqo_ywFQYxSj",
        "colab": {}
      },
      "source": [
        "# Logistic Regression\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hANwFUzhgG83",
        "colab": {}
      },
      "source": [
        "#Exam the coefficients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "evM5eiJoDHw2"
      },
      "source": [
        "## 5.2 Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "He4mlHb7hBoY",
        "colab": {}
      },
      "source": [
        "#Decision tree\n",
        "from pyspark.ml.classification import DecisionTreeClassifier "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CaE-Z_IlDKXF"
      },
      "source": [
        "## 5.3 NaiveBayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v2XL6I0t7irt",
        "colab": {}
      },
      "source": [
        "#NaiveBayes\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}